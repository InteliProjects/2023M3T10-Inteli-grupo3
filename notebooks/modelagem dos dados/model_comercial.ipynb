{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_csv('data/IM_230626_semNP.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carteira comercial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A métrica utilizada será a taxa de inadimplência, calculada pela carteira de direitos de aquisição inadimplentes dividido pelo patrimônio líquido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.dropna(subset=[\"Patrimonio_Liquido\"])\n",
    "inadimplentes = df_main[\"Carteira_Direitos_Aquisicao_Inadimplentes\"]\n",
    "patrimonio_liquido = df_main[\"Patrimonio_Liquido\"]\n",
    "taxa_inadimplencia = inadimplentes / patrimonio_liquido\n",
    "\n",
    "df_main = df_main.assign(taxa_inadimplencia_series=taxa_inadimplencia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundos = df_main[\n",
    "    (df_main['taxa_inadimplencia_series'] != 0) &\n",
    "    df_main['taxa_inadimplencia_series'].notna()\n",
    "]\n",
    "\n",
    "list(fundos['Nome_Fundo'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selecionou-se os fundos cuja taxa de inadimplência fosse válida, ou seja, apenas aqueles que a taxa de inadimplência fosse diferente de 0 e NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carteiras = [\n",
    "    'Carteira',\n",
    "    'Carteira_Industrial',\n",
    "    'Carteira_Mercado_Imobiliario',\n",
    "    'Carteira_Comercial_Total',\n",
    "    'Carteira_Comercial',\n",
    "    'Carteira_Comercial_Varejo',\n",
    "    'Carteira_Arrendamento_Mercantil',\n",
    "    'Carteira_Servicos_Total',\n",
    "    'Carteira_Servicos',\n",
    "    'Carteira_Servicos_Publicos',\n",
    "    'Carteira_Servicos_Educacionais',\n",
    "    'Carteira_Entretenimento',\n",
    "    'Carteira_Agronegocio',\n",
    "    'Carteira_Financeiro',\n",
    "    'Carteira_Credito_Pessoal_Consignado',\n",
    "    'Carteira_Credito_Corporativo',\n",
    "    'Carteira_Middle_Market',\n",
    "    'Carteira_Veiculos',\n",
    "    'Carteira_Imobiliaria_Empresarial',\n",
    "    'Carteira_Imobiliaria_Residencial',\n",
    "    'Carteira_Outros_Financeiro',\n",
    "    'Carteira_Cartao_Credito',\n",
    "    'Carteira_Factoring',\n",
    "    'Carteira_Factoring_Pessoal',\n",
    "    'Carteira_Factoring_Corporativo',\n",
    "    'Carteira_Setor_Publico',\n",
    "    'Carteira_Precatorios',\n",
    "    'Carteira_Creditos_Tributarios',\n",
    "    'Carteira_Royalties',\n",
    "    'Carteira_Outros_Setor_Publico',\n",
    "    'Carteira_Acoes_Judiciais',\n",
    "    'Carteira_Propriedade_Intelectual',\n",
    "]\n",
    "\n",
    "soma_carteiras = df_main.groupby('taxa_inadimplencia_series')[carteiras].sum()\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.barplot(data=soma_carteiras, palette='magma')\n",
    "plt.title('Taxas de Inadimplência por Carteira')\n",
    "plt.ylabel('Taxa total de inadimplência')\n",
    "plt.xlabel('Carteira')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gráfico foi plotado com todos os tipos de carteira, avaliando a taxa de inadimplência de cada segmento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_carteiras.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means\n",
    "\n",
    "O K-means é um algoritmo de agrupamento de dados que divide um conjunto de pontos em grupos (clusters) com base em suas características similares, buscando minimizar a variância dentro de cada grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "carteira_comercial = 'Carteira_Comercial_Total'\n",
    "\n",
    "fundos = df_main[df_main[carteira_comercial].notna()]\n",
    "\n",
    "X = fundos[[carteira_comercial]]\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "fundos['grupo'] = kmeans.fit_predict(X)\n",
    "\n",
    "cores = ['#FFA500', '#00CED1', '#00008B']\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "for grupo in range(3):\n",
    "    grupo_df = fundos[fundos['grupo'] == grupo]\n",
    "    ax.scatter(grupo_df.index, grupo_df[carteira_comercial],\n",
    "               color=cores[grupo], label=f'Cluster {grupo}', s=100, alpha=0.7)\n",
    "\n",
    "ax.set_title(f'{carteira_comercial}', fontsize=16)\n",
    "ax.set_xlabel('.', fontsize=14)\n",
    "ax.set_ylabel('Inadimplência', fontsize=14)\n",
    "ax.set_xticks([])\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = fundos[fundos['grupo'] == 1]\n",
    "\n",
    "cluster1 = cluster1.sort_values(by='taxa_inadimplencia_series', ascending=False)\n",
    "\n",
    "fundos_inadimplencia = cluster1.head(10)\n",
    "\n",
    "for index, row in fundos_inadimplencia.iterrows():\n",
    "    print(f'Nome do Fundo: {row[\"Nome_Fundo\"]}')\n",
    "    print(f'CNPJ do Fundo: {row[\"CNPJ\"]}')\n",
    "    print(f'Taxa de Inadimplência: {row[\"taxa_inadimplencia_series\"]}')\n",
    "    print(f'Data de competência: {row[\"Data_Competencia\"]}')\n",
    "    print('-' * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostra as maiores taxas de inadimplência do cluster 1, ou seja do cluster que agrupa as maiores taxas de inadimplência dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silhouette Score\n",
    "O Silhouette Score avalia a coesão interna dos clusters e a separação entre os clusters. Ele varia de -1 a 1, com valores mais próximos de 1 indicando um bom agrupamento. Um valor negativo sugere que os pontos podem ter sido atribuídos ao cluster errado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_avg = silhouette_score(X, fundos['grupo'])\n",
    "f'Coeficiente de Silhueta: {silhouette_avg}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilização do K-Means como Primeiro Modelo Candidato para o Problema\n",
    "\n",
    "Na busca por uma solução eficiente para o problema em questão, a escolha inicial recaiu sobre o algoritmo K-Means. O K-Means é um método de clustering (agrupamento) amplamente utilizado na análise de dados e aprendizado de máquina. Sua aplicação visa agrupar dados em clusters, onde cada cluster contém pontos de dados que são mais semelhantes entre si do que com pontos de dados de outros clusters.\n",
    "\n",
    "#### Justificativa para a Definição do K do Modelo\n",
    "\n",
    "A determinação do número de clusters (K) é crucial para o sucesso do K-Means. Nesse contexto, foi empregada a métrica do coeficiente de silhueta (silhouette score) para encontrar o valor mais adequado de K. O coeficiente de silhueta mede a similaridade média entre um objeto e seu cluster em relação aos outros clusters, variando de -1 (representando uma alocação de cluster inadequada) a 1 (indicação de uma alocação ideal).\n",
    "\n",
    "No teste realizado, o coeficiente de silhueta obteve um valor considerável de 0.9396926895140495. Esse resultado sugere que os clusters encontrados pelo K-Means são bem definidos e que a alocação de cada ponto de dados ao seu cluster é apropriada. Portanto, o valor de K utilizado nesse modelo é substancialmente apropriado para a tarefa, proporcionando uma segmentação eficaz dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DB Scan\n",
    "\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) é um algoritmo de clustering que agrupa pontos de dados próximos com base na densidade local. Ele não requer a pré-especificação do número de clusters e pode identificar clusters de diferentes tamanhos e formas. O algoritmo distingue entre pontos centrais (que têm vizinhos próximos o suficiente), pontos de borda (que estão próximos de pontos centrais) e pontos de ruído (que não pertencem a nenhum cluster). É útil para análise de dados espaciais e requer a definição adequada de parâmetros, como MinPts (número mínimo de pontos) e ε (distância máxima entre pontos) para funcionar bem em um conjunto de dados específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comercial x Serviços\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_main.dropna(subset=[\"Patrimonio_Liquido\"])\n",
    "\n",
    "inadimplentes = df_cleaned[\"Carteira_Direitos_Aquisicao_Inadimplentes\"]\n",
    "\n",
    "patrimonio_liquido = df_cleaned[\"Patrimonio_Liquido\"]\n",
    "\n",
    "taxa_inadimplencia = inadimplentes / patrimonio_liquido\n",
    "\n",
    "taxa_inadimplencia\n",
    "\n",
    "df_main = df_main.assign(taxa_inadimplencia_series=taxa_inadimplencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundos_inadimplentes = df_main[\n",
    "    (df_main['taxa_inadimplencia_series'] != 0) &\n",
    "    df_main['taxa_inadimplencia_series'].notna()\n",
    "]\n",
    "\n",
    "list(fundos_inadimplentes['Nome_Fundo'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carteiras = [\n",
    "    'Carteira_Servicos',\n",
    "    'Carteira_Comercial',\n",
    "]\n",
    "\n",
    "summed_data = df_main.groupby('taxa_inadimplencia_series')[carteiras].sum()\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.barplot(data=summed_data, palette='viridis')\n",
    "plt.title('Sum of Default Rates by Portfolio')\n",
    "plt.xlabel('Total Default Rate')\n",
    "plt.ylabel('Portfolio')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_data.head(5)\n",
    "X = summed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Selecione as colunas relevantes para o DBSCAN\n",
    "X = df_main[['Carteira_Servicos', 'Carteira_Comercial']]\n",
    "\n",
    "# Remova os valores NaN do DataFrame\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "# Amostragem aleatória de 10% dos dados\n",
    "sampled_data = X.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Aplique o StandardScaler aos dados\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(sampled_data)\n",
    "\n",
    "# Crie clusters usando DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)  # Ajuste os hiperparâmetros conforme necessário\n",
    "labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# Adicione os rótulos dos clusters ao DataFrame original\n",
    "sampled_data['Cluster_Labels'] = labels\n",
    "\n",
    "# Visualize os clusters\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=labels, cmap='viridis')\n",
    "plt.xlabel('Feature 1 (Carteira_Servicos)')\n",
    "plt.ylabel('Feature 2 (Carteira_Comercial)')\n",
    "plt.title('DBSCAN Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_id = '1teoxduT3bJAkrD0k1YIPn-mbVI83oQox'\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "gdd.download_file_from_google_drive(file_id=google_id,\n",
    "                                    dest_path = './dados_cvm.csv',\n",
    "                                    showsize = True)\n",
    "df_main = pd.read_csv('dados_cvm.csv')\n",
    "\n",
    "google_id = '1J0fF-82tDg70wjaNg2Q8OGxPikA7phqp'\n",
    "gdd.download_file_from_google_drive(file_id=google_id,\n",
    "                                    dest_path = './dados_classes.csv',\n",
    "                                    showsize = True)\n",
    "df_classes = pd.read_csv('dados_classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the \"Patrimonio_Liquido\" column and store the cleaned DataFrame in df_cleaned.\n",
    "df_cleaned = df_main.dropna(subset=[\"Patrimonio_Liquido\"])\n",
    "\n",
    "# Extract the \"Carteira_Direitos_Aquisicao_Inadimplentes\" column from the cleaned DataFrame.\n",
    "inadimplentes = df_cleaned[\"Carteira_Direitos_Aquisicao_Inadimplentes\"]\n",
    "\n",
    "# Extract the \"Patrimonio_Liquido\" column from the cleaned DataFrame.\n",
    "patrimonio_liquido = df_cleaned[\"Patrimonio_Liquido\"]\n",
    "\n",
    "# Calculate the default rate by dividing the number of inadimplentes by the patrimonio_liquido.\n",
    "taxa_inadimplencia = inadimplentes / patrimonio_liquido\n",
    "\n",
    "# Display the calculated default rate.\n",
    "taxa_inadimplencia\n",
    "\n",
    "# Add a new column named \"taxa_inadimplencia_series\" to the original df_informe_mensal DataFrame\n",
    "# and assign it the values of the calculated default rate.\n",
    "df_main = df_main.assign(taxa_inadimplencia_series=taxa_inadimplencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundos_inadimplentes = df_main[\n",
    "    (df_main['taxa_inadimplencia_series'] != 0) &\n",
    "    df_main['taxa_inadimplencia_series'].notna()\n",
    "]\n",
    "\n",
    "list(fundos_inadimplentes['Nome_Fundo'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carteiras = [\n",
    "    'Carteira_Comercial',\n",
    "    'Carteira_Comercial_Varejo',\n",
    "]\n",
    "\n",
    "summed_data = df_main.groupby('taxa_inadimplencia_series')[carteiras].sum()\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.barplot(data=summed_data, palette='viridis')\n",
    "plt.title('Sum of Default Rates by Portfolio')\n",
    "plt.xlabel('Total Default Rate')\n",
    "plt.ylabel('Portfolio')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_data.head(5)\n",
    "X = summed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CARTEIRA COMERCIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "bandwidth = estimate_bandwidth(X, quantile=0.2, n_samples=500)\n",
    "\n",
    "# Criar uma instância do MeanShift com a largura de banda estimada\n",
    "ms = MeanShift(bandwidth=bandwidth)\n",
    "\n",
    "# Ajustar o modelo aos dados\n",
    "ms.fit(X)\n",
    "\n",
    "# Obter os rótulos dos clusters e os centros dos clusters\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "# Plotar os pontos de dados e os centros dos clusters\n",
    "plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=labels)\n",
    "plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], s=300, linewidths=3, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_data[\"Cluster_Labels\"] = labels\n",
    "summed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(summed_data[\"Cluster_Labels\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecionar_cluster(n_cluster):\n",
    "  df_cluster = summed_data.loc[summed_data[\"Cluster_Labels\"]==n_cluster]\n",
    "  return df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selecionar_cluster(0) #Adicionar o número de cluster que você gostaria de verificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filtrar os dados para manter apenas os valores no intervalo de 0 a 5\n",
    "filtered_data = summed_data[(summed_data[\"Cluster_Labels\"] >= 0) & (summed_data[\"Cluster_Labels\"] <= 5)]\n",
    "\n",
    "# Contar a ocorrência de cada valor e criar o gráfico de barras\n",
    "value_counts = filtered_data[\"Cluster_Labels\"].value_counts()\n",
    "value_counts = value_counts.sort_index()  # Ordenar pelo valor do índice\n",
    "\n",
    "# Plotar o gráfico de barras\n",
    "value_counts.plot(kind='bar')\n",
    "plt.title('Cluster Labels no intervalo de 0 a 5')\n",
    "plt.xlabel('Cluster Labels')\n",
    "plt.ylabel('Contagem')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_s_0 = summed_data.loc[summed_data[\"Cluster_Labels\"]!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos algumas conclusões com esse gráfico.\n",
    "\n",
    "1. Os dados estão extremamente espaçados e dispersos;\n",
    "\n",
    "2. Maior concentração de números zerados estão no cluster 0;\n",
    "\n",
    "3. O método de MeanShift pode não ser o melhor para os dados, pois ele busca a média dos clusters de acordo com uma função de densidade. No nosso caso, foi o 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escolha do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao analisar a separação dos clusters da carteira comercial entre os algoritmos, o modelo escolhido foi o K-Means, pelo fato da sua separação ter sido uma das mais lógicas em relação ao nível de inadimplência, apesar do modelo não classificar os fundos relacionando-os diretamente com as features. Logo, é possível concluir que nenhum dos modelos candidatos apresentou uma separação muito clara ou significativa entre os clusters. Enquanto o K-Means e o Mini Batch K-Means realizaram uma separação em 3 partes proporcionais em relação ao target, o Mean Shift e o DBSCAN acabaram formando um cluster muito grande por conta de uma densidade de dados muito alta em determina, resultando em uma divisão muito desigual e também pouco significativa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
